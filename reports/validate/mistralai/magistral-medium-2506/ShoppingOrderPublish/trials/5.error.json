{
  "type": "error",
  "error": {
    "status": 400,
    "headers": {
      "access-control-allow-origin": "*",
      "cf-ray": "94e129f80cb72208-MAN",
      "connection": "keep-alive",
      "content-length": "323",
      "content-type": "application/json",
      "date": "Wed, 11 Jun 2025 12:38:10 GMT",
      "server": "cloudflare",
      "vary": "Accept-Encoding",
      "x-clerk-auth-message": "Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)",
      "x-clerk-auth-reason": "token-invalid",
      "x-clerk-auth-status": "signed-out"
    },
    "error": {
      "message": "This endpoint's maximum context length is 40960 tokens. However, you requested about 52834 tokens (52544 of text input, 290 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.",
      "code": 400,
      "metadata": {
        "provider_name": null
      }
    },
    "code": 400,
    "name": "Error",
    "message": "400 This endpoint's maximum context length is 40960 tokens. However, you requested about 52834 tokens (52544 of text input, 290 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.",
    "stack": "Error: 400 This endpoint's maximum context length is 40960 tokens. However, you requested about 52834 tokens (52544 of text input, 290 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.\n    at APIError.generate (file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/node_modules/.pnpm/openai@4.91.1/node_modules/openai/error.mjs:41:20)\n    at OpenAI.makeStatusError (file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/node_modules/.pnpm/openai@4.91.1/node_modules/openai/core.mjs:295:25)\n    at OpenAI.makeRequest (file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/node_modules/.pnpm/openai@4.91.1/node_modules/openai/core.mjs:339:30)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async process (file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/dist/index.mjs:329:24)\n    at async tryValidateExperiment (file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/dist/index.mjs:313:17)\n    at async file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/dist/index.mjs:1211:23\n    at async Promise.all (index 4)\n    at async file:///Users/ryoppippi/ghq/github.com/wrtnlabs/benchmark/dist/index.mjs:1209:30\n    at async Promise.all (index 9)"
  },
  "started_at": "2025-06-11T12:38:09.658Z",
  "completed_at": "2025-06-11T12:38:10.670Z",
  "previous": []
}